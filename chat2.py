import streamlit as st
import os
import json
import time
import pandas as pd
import re 
import nest_asyncio

from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.schema.document import Document
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

nest_asyncio.apply()

os.environ["AZURE_OPENAI_API_KEY"] = 'd8e93330e8384f06aa1c8ace726af49e'
os.environ["AZURE_OPENAI_ENDPOINT"] = 'https://dataiku-gpt4ommi.openai.azure.com/'

EMBEDDING_MODEL_NAME = "BAAI/bge-m3"
JSON_PATH = "Jsonfile/M.JSON"
CHAT_HISTORY_FILE = "chat_history_policy.json"
EXCEL_FILE_PATH = r'Data real/Car rate book.xlsx'
VECTOR_STORE_PATH = "car_rate_vectorstore"
VECTOR_STORE_PATH_POLICY = "carpolicyindex"

st.set_page_config(
    page_title="Srisawad Chat",
    page_icon="https://companieslogo.com/img/orig/SAWAD.BK-18d7b4df.png?t=1720244493",
    layout="centered"
)

def apply_custom_css():
    st.markdown("""
        <style>
            [data-testid="stSidebar"] {
                min-width: 450px !important;
                max-width: 450px !important;
                width: 450px !important;
                transition: all 0.3s ease-in-out;
            }
            [data-testid="stSidebarNav"] { display: none; }
            section[data-testid="stSidebarContent"] {
                width: 450px !important;
                padding-right: 1rem;
            }
            button[data-testid="baseButton-secondary"] { visibility: hidden; }
            .stButton button {
                height: 50px;
                font-size: 16px;
            }
            [data-testid="stMarkdownContainer"] h1 {
                font-size: 24px;
                padding: 10px 0;
                text-align: center;
            }
            .stSubheader {
                font-size: 18px;
                padding: 5px 0;
            }
            [data-testid="stSidebar"][aria-expanded="false"] {
                margin-left: -450px;
            }
            .stButton.delete-button button {
                background-color: transparent;
                color: #ff4b4b;
                border: none;
                padding: 0;
                height: 30px;
                width: 30px;
                border-radius: 50%;
            }
            .stButton.delete-button button:hover {
                background-color: #ffeded;
            }
            div.st-cc { padding: 0.25rem; }
            div.stRadio > label {
                background-color: #f0f2f6;
                padding: 10px 15px;
                border-radius: 5px;
                margin-right: 10px;
                cursor: pointer;
                transition: background-color 0.3s;
            }
            div.stRadio > label:hover { background-color: #e0e2e6; }
            div.stRadio [data-testid="stMarkdownContainer"] p {
                font-size: 16px;
                font-weight: 500;
            }
        </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def load_car_data(file_path):
    if not os.path.exists(file_path):
        return pd.DataFrame()
    df = pd.read_excel(file_path, header=0, dtype=str).fillna('')
    df['MANUYR'] = pd.to_numeric(df['MANUYR'], errors='coerce').astype('Int64')
    df['RATE'] = pd.to_numeric(df['RATE'], errors='coerce').astype('Int64')
    df['FDATEA'] = pd.to_datetime(df['FDATEA'], format='%d-%b-%y', errors='coerce')
    df['LDATEA'] = pd.to_datetime(df['LDATEA'], format='%d-%b-%y', errors='coerce')
    return df

def format_car_row(row):
    columns_labels = {
        'TYPECOD': 'Brand', 'MODELCOD': 'Main Model', 'MODELDESC': 'Sub Model',
        'MANUYR': 'Year', 'GEAR': 'Transmission', 'GCODE': 'Vehicle Type',
        'PRODUCT GROUP': 'Product Group', 'RATE': 'Appraisal Price'
    }
    parts = []
    for col, label in columns_labels.items():
        value = row.get(col)
        if pd.notna(value) and str(value).strip():
            if col in ['RATE', 'MANUYR']:
                num_value = int(value)
                if num_value > 0:
                    formatted_value = f"{num_value:,}" if col == 'RATE' else str(num_value)
                    parts.append(f"{label}: {formatted_value}")
            else:
                parts.append(f"{label}: {value}")
    return ", ".join(parts) if parts else "Insufficient information"

def analyze_question_agent(user_input):
    car_keywords = ["car", "vehicle", "price", "truck", "motorcycle", "brand", "model", 
                   "‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå", "‡∏£‡∏ñ‡πÄ‡∏Å‡πã‡∏á", "‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞", "‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå", "‡∏£‡∏≤‡∏Ñ‡∏≤"]
    policy_keywords = ["loan", "credit", "policy", "interest", "requirement", "‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠", 
                      "‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ", "‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢", "‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô", "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "ctvgmhl"]
    car_count = sum(1 for word in car_keywords if word.lower() in user_input.lower())
    policy_count = sum(1 for word in policy_keywords if word.lower() in user_input.lower())
    if car_count > policy_count:
        data_source = "Car Rate"
        reasoning = f"Keyword matching: {car_count} car keywords vs {policy_count} policy keywords"
        return data_source, user_input, reasoning
    llm = AzureChatOpenAI(
        openai_api_version="2024-12-01-preview",
        azure_deployment="dataiku-ssci-gpt-4o", 
        temperature=1.0, 
        max_tokens=4096,  
    )
    template = """
    You are an AI agent responsible for analyzing user questions and determining whether they should be directed to 
    the Car Rate book search or Credit Policy search. 
    
    User question: {question}
    
    Please output your answer in the format:
    DATA_SOURCE: [Car Rate or Credit Policy]
    REFORMULATED_QUESTION: [Reformulated question if needed, or the original question if clear]
    REASONING: [Brief explanation of your decision]
    LANGUAGE: [Thai or English - determine based on the language of the input question]
    """
    prompt = PromptTemplate(template=template, input_variables=["question"])
    agent_chain = prompt | llm | StrOutputParser()
    result = agent_chain.invoke({"question": user_input})
    lines = result.strip().split('\n')
    data_source = None
    reformulated_question = user_input
    reasoning = ""
    for line in lines:
        if line.startswith('DATA_SOURCE:'):
            data_source = line.replace('DATA_SOURCE:', '').strip()
        elif line.startswith('REFORMULATED_QUESTION:'):
            reformulated_question = line.replace('REFORMULATED_QUESTION:', '').strip()
        elif line.startswith('REASONING:'):
            reasoning = line.replace('REASONING:', '').strip()
    if not data_source:
        data_source = "Credit Policy" if policy_count >= car_count else "Car Rate"
    if any(keyword in user_input.lower() for keyword in car_keywords) and not data_source:
        return "Car Rate", user_input, "Fallback: Basic keyword detection"
    return data_source, reformulated_question, reasoning

def build_car_response(answer, product_group=None, gcode=None):
    return f"""
{answer}
"""

@st.cache_resource
def create_embeddings_model():
    class SafeHuggingFaceBgeEmbeddings(HuggingFaceBgeEmbeddings):
        def embed_query(self, text):
            if text is None:
                text = ""
            return super().embed_query(text)
    return SafeHuggingFaceBgeEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True},
        query_instruction="Represent this query for retrieving relevant documents: "
    )

def load_or_create_faiss_index(documents, embed_model, index_path):
    if os.path.exists(index_path):
        vectorstore = FAISS.load_local(index_path, embed_model)
    else:
        vectorstore = FAISS.from_documents(documents, embed_model)
        vectorstore.save_local(index_path)
    return vectorstore

@st.cache_resource
def create_car_vector_store():
    car_data = load_car_data(EXCEL_FILE_PATH)
    texts = [format_car_row(row) for _, row in car_data.iterrows()]
    documents = [Document(page_content=text, metadata={"id": str(i)}) for i, text in enumerate(texts)]
    embed_model = create_embeddings_model()
    vector_store = load_or_create_faiss_index(documents, embed_model, VECTOR_STORE_PATH)
    return vector_store, embed_model

@st.cache_resource
def build_car_rag_chain():
    vector_store, _ = create_car_vector_store()
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    llm = AzureChatOpenAI(
        openai_api_version="2024-12-01-preview",
        azure_deployment="dataiku-ssci-gpt-4o",
        temperature=1.0,
        max_tokens=4096, 
    )
    template = """
    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏Ç‡∏≠‡∏á‡∏®‡∏£‡∏µ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå (Srisawad's car pricing information) ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô 'Relevant car pricing information (Context)' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Mapping ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Context ‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î

    **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Mapping (Data Schema and Mappings):**

    *   **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏•‡∏±‡∏Å (Key Column Meanings):**
        *   `TYPECOD`: ‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (Brand)
        *   `MODELCOD`: ‡∏£‡∏∏‡πà‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (Main Model)
        *   `MODELDESC`: ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏∏‡πà‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (Sub Model/Description)
        *   `MANUYR`: ‡∏õ‡∏µ‡∏ú‡∏•‡∏¥‡∏ï (Manufacturing Year)
        *   `RATE`: ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (Appraisal Price) - **‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á**
        *   `GCODE`: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå (Sub-category Code) - **‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**
        *   `PRODUCT GROUP`: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (Main Category Code) - **‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢**
        *   `GEAR`: ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô (Transmission: Auto, Manual)
        *   `FDATEA`: ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤
        *   `LDATEA`: ‡∏ß‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤

    *   **Mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GCODE (‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏¢‡πà‡∏≠‡∏¢):**
        *   `CA`: ‡∏£‡∏ñ‡πÄ‡∏Å‡πã‡∏á (2-5 ‡∏õ‡∏£‡∏∞‡∏ï‡∏π)
        *   `P4`: ‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞ (4 ‡∏õ‡∏£‡∏∞‡∏ï‡∏π)
        *   `P2`: ‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞ (‡πÅ‡∏Ñ‡∏õ)
        *   `P1`: ‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞ (‡∏ï‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        *   `MC`: ‡∏£‡∏ñ‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå
        *   `FT`: ‡∏£‡∏ñ‡πÑ‡∏ñ
        *   `T4`: ‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å (4 ‡∏•‡πâ‡∏≠)
        *   `T6`: ‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å (6 ‡∏•‡πâ‡∏≠)
        *   `T10`: ‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å (10 ‡∏•‡πâ‡∏≠)
        *   `T12`: ‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å (12 ‡∏•‡πâ‡∏≠)
        *   `VA`: ‡∏£‡∏ñ‡∏ï‡∏π‡πâ
        *   `BS`: ‡∏£‡∏ñ‡∏ö‡∏±‡∏™
        *   `HV`: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏±‡∏Å‡∏£‡∏Å‡∏•‡∏´‡∏ô‡∏±‡∏Å
        *   `OT`: ‡∏£‡∏ñ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
        *   `N01`: ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏´‡∏•‡∏±‡∏Å-‡∏£‡∏≠‡∏á
        *   `G01`: ‡∏£‡∏ñ‡πÑ‡∏ñ‡πÇ‡∏£‡∏ï‡∏≤‡∏£‡∏µ‡πà
        *   `G03`: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏©‡∏ï‡∏£
        *   `LA`: ‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô‡πÄ‡∏õ‡∏•‡πà‡∏≤
        *   `LH`: ‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏¥‡πà‡∏á‡∏õ‡∏•‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á
        *   `IS`: ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô
        *   `P04`: ‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• (‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó)
        *   `HR`: ‡∏£‡∏ñ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≤‡∏ß

    *   **Mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PRODUCT GROUP (‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å):**
        *   `A`: NanoFinance
        *   `P`: PLOAN
        *   `T`: Truck (‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å)
        *   `M`: Motocycle (‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå)
        *   `V`: ‡∏£‡∏ñ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≤‡∏ß
        *   `G`: Kubota (‡∏£‡∏ñ‡πÑ‡∏ñ‡πÄ‡∏î‡∏¥‡∏ô‡∏ï‡∏≤‡∏°/‡πÄ‡∏Å‡∏©‡∏ï‡∏£)
        *   `H`: House (‡∏ö‡πâ‡∏≤‡∏ô)
        *   `L`: Land (‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô)
        *   `I`: Insurance (‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô)
        *   `C`: Car (‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå - ‡πÄ‡∏Å‡πã‡∏á, ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞, ‡∏ï‡∏π‡πâ)

    ---

    **Relevant car pricing information (Context):**
    {context}

    **User question:**
    {question}

    ---

    **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö (Instructions):**

    1.  **‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Context ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:** ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
    2.  **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Schema:** ‡∏à‡∏≤‡∏Å Context ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (`{question}`) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Mapping ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô** ‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
        *   ‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏£‡∏ñ (‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏£‡∏ß‡∏° `TYPECOD`, `MODELCOD`, `MODELDESC`, `MANUYR` ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô Context)
        *   ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `RATE`)
        *   **‡∏£‡∏´‡∏±‡∏™**‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏¢‡πà‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `GCODE`)
        *   **‡∏£‡∏´‡∏±‡∏™**‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏´‡∏•‡∏±‡∏Å (‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå `PRODUCT GROUP`)
    3.  **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö (Output Format):** ‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ *‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô*:

        ```
        ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Ç‡∏≠‡∏á [‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context] ‡∏£‡∏≤‡∏Ñ‡∏≤ [‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô(RATE)‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context] ‡∏ö‡∏≤‡∏ó
        ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏¢‡πà‡∏≠‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (GCODE) : [GCODE ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context] ([‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ GCODE ‡∏à‡∏≤‡∏Å Mapping ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô])
        ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô (PRODUCT GROUP) : [PRODUCT GROUP ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context] ([‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ PRODUCT GROUP ‡∏à‡∏≤‡∏Å Mapping ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô])
        ```

        *   ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà `[‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context]` ‡πÅ‡∏•‡∏∞ `[‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô(RATE)‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context]` ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÄ‡∏à‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏à‡∏≤‡∏Å `{context}`.
        *   ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö `[GCODE ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context]` ‡πÅ‡∏•‡∏∞ `[PRODUCT GROUP ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô Context]`: ‡πÉ‡∏™‡πà **‡∏£‡∏´‡∏±‡∏™** ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å `{context}`.
        *   ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö `([‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢...‡∏à‡∏≤‡∏Å Mapping ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô])`: **‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å** ‡πÑ‡∏î‡πâ‡∏£‡∏´‡∏±‡∏™ `GCODE` ‡πÅ‡∏•‡∏∞ `PRODUCT GROUP` ‡∏à‡∏≤‡∏Å `{context}` ‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô** ‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô **"Mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GCODE"** ‡πÅ‡∏•‡∏∞ **"Mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PRODUCT GROUP"** ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ *‡πÉ‡∏ô‡∏û‡∏£‡∏≠‡∏°‡∏ï‡πå‡∏ô‡∏µ‡πâ* ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏£‡∏´‡∏±‡∏™.
        *   **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö *‡∏£‡∏´‡∏±‡∏™* (`GCODE` ‡∏´‡∏£‡∏∑‡∏≠ `PRODUCT GROUP`) ‡πÉ‡∏ô Context ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏ñ‡∏£‡∏∏‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô `GCODE : ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•`). ‡∏´‡∏≤‡∏Å‡∏û‡∏ö *‡∏£‡∏´‡∏±‡∏™* ‡πÅ‡∏ï‡πà *‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢* ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô Mapping ‡∏Ç‡∏≠‡∏á‡∏û‡∏£‡∏≠‡∏°‡∏ï‡πå‡∏ô‡∏µ‡πâ (‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤ Mapping ‡∏Ñ‡∏£‡∏ö) ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏£‡∏´‡∏±‡∏™‡πÅ‡∏•‡∏∞‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏ß‡πà‡∏≤‡∏á `()` ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ `(‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏ô Mapping)`.
        *   ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏≤‡∏Ñ‡∏≤‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡∏´‡∏ô‡πà‡∏ß‡∏¢ "‡∏ö‡∏≤‡∏ó" ‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)

    4.  **‡∏†‡∏≤‡∏©‡∏≤ (Language):**
        *   ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° `{question}` ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠ 3 ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        *   ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° `{question}` ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏à‡∏≤‡∏Å Mapping (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏™‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Code ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÉ‡∏ô Mapping ‡πÄ‡∏ä‡πà‡∏ô:
            ```
            Price of [Car Model Found in Context]: [RATE Found in Context] Baht
            Sub-category of collateral (GCODE): [GCODE Found in Context] ([GCODE Description from Mapping])
            Main category of collateral (PRODUCT GROUP): [PRODUCT GROUP Found in Context] ([PRODUCT GROUP Description from Mapping])
            ```
            (‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ "Not specified" ‡∏´‡∏£‡∏∑‡∏≠ "N/A". ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ Description ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà Code ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ Code ‡∏Å‡∏±‡∏ö `()`)

    5.  **‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡∏¢:** ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î‡πÜ ‡πÉ‡∏ô `{context}` ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏°‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà: "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á" (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢) ‡∏´‡∏£‡∏∑‡∏≠ "No relevant information found" (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) **‡∏´‡πâ‡∏≤‡∏°**‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠ 3

    **Answer:**
    """
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

def display_normal_message(message_placeholder, text):
    message_placeholder.markdown(text)

def clean_assistant_response(message_placeholder, text):
    if "No relevant information found" in text or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á" in text:
        message_placeholder.markdown("I don't have specific information about this topic in my knowledge base.")
        return
    lines = text.split('\n')
    filtered_lines = []
    skip_section = False
    for line in lines:
        if "No specific sources found" in line or "No data available" in line:
            continue
        if "Additional details:" in line and ("Not specified" in "".join(lines[lines.index(line):lines.index(line)+4])):
            skip_section = True
            continue
        if skip_section and line.strip() == "":
            skip_section = False
            continue
        if skip_section:
            continue
        filtered_lines.append(line)
    cleaned_text = "\n".join(filtered_lines)
    if "**Reference Source:**" in cleaned_text and len(cleaned_text.split("**Reference Source:**")[1].strip()) < 5:
        cleaned_text = cleaned_text.split("**Reference Source:**")[0].strip()
    message_placeholder.markdown(cleaned_text)

def format_value(value):
    if isinstance(value, list):
        return "\n".join([f"- {item}" for item in value]) if value else "No data available"
    elif isinstance(value, dict):
        return "\n".join([f"  {k}: {format_value(v)}" for k, v in value.items()]) if value else "No data available"
    else:
        return str(value or "No data available").replace("\\n", "\n")
    
def parse_json_to_docs(data, parent_key="", docs=None):
    if docs is None:
        docs = []
    if isinstance(data, dict):
        current_topic = data.get("‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", data.get("‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢", parent_key.strip('.')))
        content_parts = []
        metadata = {"source": parent_key.strip('.')}
        for key, value in data.items():
            current_key = f"{parent_key}{key}" if parent_key else key
            if isinstance(value, (dict, list)) and key not in ["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢"]:
                parse_json_to_docs(value, f"{current_key}.", docs)
            elif key not in ["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢"]:
                readable_key = key.replace("_", " ").replace("‡πÄ‡∏õ‡πâ‡∏≤ ", "Target ")
                content_parts.append(f"{readable_key}: {format_value(value)}")
        if content_parts:
            page_content = f"Topic: {current_topic}\n" + "\n".join(content_parts)
            docs.append(Document(page_content=page_content.strip(), metadata=metadata))
    elif isinstance(data, list) and parent_key:
        page_content = f"Topic: {parent_key.strip('.')}\n{format_value(data)}"
        metadata = {"source": parent_key.strip('.')}
        docs.append(Document(page_content=page_content.strip(), metadata=metadata))
    return docs

def display_resource_cards():
    if st.session_state.detected_mode == "Car Rate":
        st.markdown("""
            <div style="margin-top: 20px;">
                <div style="display: flex; justify-content: center; gap: 20px;">
                    <a href="https://docs.google.com/spreadsheets/d/1Zxf-8sMZOwo36IWoSPXnyhRN02BFXPVGeLYz5h6t_1s/edit?usp=sharing" target="_blank" style="text-decoration: none; color: inherit;">
                        <div style="text-align: center; width: 150px;">
                            <div style="background-color: #f8f9fa; border-radius: 8px; padding: 15px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); display: flex; flex-direction: column; align-items: center; height: 150px;">
                                <img src="https://cdn-icons-png.flaticon.com/512/888/888850.png" width="64" height="64">
                                <p style="margin-top: 10px; font-weight: 500; font-size: 14px;">Car rate book</p>
                            </div>
                        </div>
                    </a>
                </div>
            </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
            <div style="margin-top: 20px;">
                <div style="display: flex; justify-content: center; gap: 20px;">
                    <a href="https://docs.google.com/spreadsheets/d/10Ol2r3_ZTkSf9KSGCjLjs9J4RepArO3tepwhErKyptI/edit?usp=sharing" target="_blank" style="text-decoration: none; color: inherit;">
                        <div style="text-align: center; width: 150px;">
                            <div style="background-color: #f8f9fa; border-radius: 8px; padding: 15px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); display: flex; flex-direction: column; align-items: center; height: 150px;">
                                <img src="https://cdn-icons-png.flaticon.com/512/888/888850.png" width="64" height="64">
                                <p style="margin-top: 10px; font-weight: 500; font-size: 14px;">Credit Policy - CTVGMHL</p>
                            </div>
                        </div>
                    </a>
                </div>
            </div>
        """, unsafe_allow_html=True)

def load_chat_history():
    chat_dir = os.path.dirname(CHAT_HISTORY_FILE)
    if chat_dir:
        os.makedirs(chat_dir, exist_ok=True)
    if not os.path.exists(CHAT_HISTORY_FILE):
        with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump({"chats": {}}, f)
        return {"chats": {}}
    with open(CHAT_HISTORY_FILE, "r", encoding="utf-8") as f:
        content = f.read()
        return json.loads(content) if content else {"chats": {}}

def save_chat_history(history):
    with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2, default=str)

def save_chat_to_history(chat_id, role, content):
    history = load_chat_history()
    if "chats" not in history:
        history["chats"] = {}
    if chat_id not in history["chats"]:
        history["chats"][chat_id] = {
            "messages": [],
            "created_at": str(pd.Timestamp.now())
        }
    elif "messages" not in history["chats"][chat_id]:
        history["chats"][chat_id]["messages"] = []
    history["chats"][chat_id]["messages"].append({
        "role": role,
        "content": content,
        "timestamp": str(pd.Timestamp.now())
    })
    save_chat_history(history)

def delete_chat_history():
    with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump({"chats": {}}, f)
    return True

def delete_single_chat(chat_id):
    history = load_chat_history()
    if "chats" in history and chat_id in history["chats"]:
        del history["chats"][chat_id]
        save_chat_history(history)
        return True
    return False

@st.cache_resource
def load_llm():
    return AzureChatOpenAI(
        openai_api_version="2024-12-01-preview",
        azure_deployment="dataiku-ssci-gpt-4o",
        temperature=1.0,
        max_tokens=4096,
    )

@st.cache_resource
def load_policy_data():
    embed_model = create_embeddings_model()
    try:
        vectorstore = FAISS.load_local(
            VECTOR_STORE_PATH_POLICY,
            embed_model,
            allow_dangerous_deserialization=True  # <-- IMPORTANT!
        )
    except Exception as e:
        st.error(f"Error loading policy vector store: {e}")
        # fallback or raise
        raise
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    prompt_template = """
        ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç AI ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏≠‡∏á‡∏®‡∏£‡∏µ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå (Srisawad's credit policies) ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ
        ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô 'Relevant Information (Context)' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Context ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏´‡∏£‡∏∑‡∏≠ "‡πÄ‡∏õ‡πâ‡∏≤" ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏õ‡πâ‡∏≤ M, ‡πÄ‡∏õ‡πâ‡∏≤ ‡∏Å, ‡πÄ‡∏õ‡πâ‡∏≤ F, ‡πÄ‡∏õ‡πâ‡∏≤ H, ‡πÄ‡∏õ‡πâ‡∏≤ L) ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏¢‡πà‡∏≠‡∏¢, ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£, ‡∏Ç‡πâ‡∏≠‡∏´‡πâ‡∏≤‡∏°, ‡πÅ‡∏•‡∏∞‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô

        ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©

        Relevant Information (Context):
        {context}

        Question:
        {input}

        ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
        1.  **‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å 'Relevant Information (Context)' ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        2.  **‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠ ("‡πÄ‡∏õ‡πâ‡∏≤"):** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏£‡∏∞‡∏ö‡∏∏ "‡πÄ‡∏õ‡πâ‡∏≤" ‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡∏™‡∏¥‡∏ô‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πâ‡∏≤ M, ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÄ‡∏õ‡πâ‡∏≤ ‡∏Å) ‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö "‡πÄ‡∏õ‡πâ‡∏≤" ‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ "‡πÄ‡∏õ‡πâ‡∏≤" ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å "‡πÄ‡∏õ‡πâ‡∏≤" ‡πÉ‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á "‡πÄ‡∏õ‡πâ‡∏≤" ‡∏ï‡πà‡∏≤‡∏á‡πÜ (‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ)
        3.  **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥:** ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏á‡∏ß‡∏î, ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏ú‡∏π‡πâ‡∏Å‡∏π‡πâ/‡∏ú‡∏π‡πâ‡∏Ñ‡πâ‡∏≥, ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ, ‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏ñ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î, ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ñ‡∏∑‡∏≠‡∏Ñ‡∏£‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô, ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏ä‡∏µ‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô
        4.  **‡∏£‡∏∞‡∏ö‡∏∏‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô:** ‡∏´‡∏≤‡∏Å‡πÉ‡∏ô Context ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏ "‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô" ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•/‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ô‡∏∏‡∏°‡∏±‡∏ï‡∏¥‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢
        5.  **‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:** ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô Context ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤ "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤" ‡∏´‡∏£‡∏∑‡∏≠ "This information is not found in the provided context"
        6.  **‡∏†‡∏≤‡∏©‡∏≤:** ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏° (‡πÑ‡∏ó‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
        7.  **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö:** ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏° Context

        Answer:
        """
    llm = load_llm()
    prompt = ChatPromptTemplate.from_template(prompt_template)
    document_chain = create_stuff_documents_chain(llm, prompt)
    return create_retrieval_chain(retriever, document_chain)

def get_chat_preview(content, max_length=30):
    if not isinstance(content, str):
        content = str(content)
    words = content.split()
    preview = ' '.join(words[:5])
    return f"{preview[:max_length]}..." if len(preview) > max_length else (preview or "...")

def manage_chat_history():
    with st.sidebar:
        apply_custom_css()
        st.markdown('<h1 style="text-align: center; font-size: 32px;">Chat History</h1>', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üó™ New Chat", type="primary", use_container_width=True):
                st.session_state.messages = []
                st.session_state.current_chat_id = f"chat_{int(time.time())}_{os.urandom(4).hex()}"
                st.session_state.session_vector_store = None
                st.session_state.detected_mode = None
                st.rerun()
        with col2:
            if st.button("üóëÔ∏è Delete All", type="secondary", use_container_width=True):
                if delete_chat_history():
                    st.session_state.messages = []
                    st.session_state.current_chat_id = f"chat_{int(time.time())}_{os.urandom(4).hex()}"
                    st.session_state.session_vector_store = None
                    st.session_state.detected_mode = None
                    st.rerun()
        st.divider()
        history = load_chat_history()
        chats = history.get("chats", {})
        if not chats:
            st.caption("No past chats.")
        else:
            chat_list = []
            for chat_id, chat_info in chats.items():
                messages = chat_info.get("messages", [])
                created_at_str = chat_info.get("created_at")
                created_at = pd.to_datetime(created_at_str) if created_at_str else pd.Timestamp.now()
                first_user_message = "..."
                for msg in messages:
                    if msg.get("role") == "user":
                        first_user_message = msg.get("content", "...")
                        break
                chat_list.append((created_at, chat_id, first_user_message))
            chat_list.sort(key=lambda x: x[0], reverse=True)
            chats_by_date = {}
            for created_at, chat_id, first_message in chat_list:
                date_str = created_at.strftime('%Y-%m-%d')
                if date_str not in chats_by_date:
                    chats_by_date[date_str] = []
                chats_by_date[date_str].append((chat_id, first_message))
            for date_str in sorted(chats_by_date.keys(), reverse=True):
                st.markdown(f'<div class="chat-date-header">{date_str}</div>', unsafe_allow_html=True)
                for chat_id, first_message in chats_by_date[date_str]:
                    col_btn, col_del = st.columns([0.85, 0.15])
                    with col_btn:
                        preview_text = get_chat_preview(first_message)
                        if st.button(preview_text, key=f"load_{chat_id}", use_container_width=True):
                            st.session_state.messages = [
                                {"role": msg["role"], "content": msg["content"]}
                                for msg in chats.get(chat_id, {}).get("messages", [])
                            ]
                            st.session_state.current_chat_id = chat_id
                            st.rerun()
                    with col_del:
                        if st.button("üóëÔ∏è", key=f"delete_{chat_id}", help="Delete chat"):
                            if delete_single_chat(chat_id):
                                if st.session_state.get("current_chat_id") == chat_id:
                                    st.session_state.current_chat_id = f"chat_{int(time.time())}_{os.urandom(4).hex()}"
                                    st.session_state.messages = []
                                st.rerun()

def extract_vehicle_info(response, car_data):
    product_group = ""
    gcode = ""
    pg_patterns = [
        r"PRODUCT GROUP[:\s]+([A-Z])",
        r"‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå[:\s]+([A-Z])"
    ]
    gcode_patterns = [
        r"GCODE[:\s]+([A-Za-z0-9]+)",
        r"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ[:\s]+([A-Za-z0-9]+)"
    ]
    for pattern in pg_patterns:
        matches = re.search(pattern, response)
        if matches:
            product_group = matches.group(1)
            break
    for pattern in gcode_patterns:
        matches = re.search(pattern, response)
        if matches:
            gcode = matches.group(1)
            break
    if not product_group:
        response_lower = response.lower()
        if any(keyword in response_lower for keyword in ['motorcycle', '‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÑ‡∏ã‡∏Ñ‡πå']):
            product_group = 'M'
            gcode = gcode or 'MC'
        elif any(keyword in response_lower for keyword in ['truck', '‡∏£‡∏ñ‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å']):
            product_group = 'T'
            gcode = gcode or 'T10'
        elif any(keyword in response_lower for keyword in ['car', 'sedan', '‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå', '‡∏£‡∏ñ‡πÄ‡∏Å‡πã‡∏á']):
            product_group = 'C'
            gcode = gcode or 'CA'
        elif any(keyword in response_lower for keyword in ['pickup', '‡∏£‡∏ñ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞']):
            product_group = 'C'
            gcode = 'P1'
    product_group = product_group or 'C'
    gcode = gcode or 'CA'
    return product_group, gcode

def route_query_to_appropriate_chain(user_input):
    data_source, reformulated_question, reasoning = analyze_question_agent(user_input)
    st.session_state.detected_mode = data_source
    return reformulated_question, data_source, reasoning

def main():
    st.session_state.setdefault("messages", [])
    st.session_state.setdefault("current_chat_id", f"chat_{int(time.time())}_{os.urandom(4).hex()}")
    st.session_state.setdefault("chat_mode", "Auto-detect")
    st.session_state.setdefault("chat_mode_selected", True)
    st.session_state.setdefault("detected_mode", None)
    with st.spinner("Loading resources..."):
        car_data = load_car_data(EXCEL_FILE_PATH)
    manage_chat_history()
    st.markdown(
        """
        <div style="text-align: center;">
            <img src="https://cdn-cncpm.nitrocdn.com/DpTaQVKLCVHUePohOhFgtgFLWoUOmaMZ/assets/images/optimized/rev-5be2389/www.sawad.co.th/wp-content/uploads/2020/12/logo.png" width="250">
            <h1 style="font-size: 40px; font-weight: bold; margin-top: 10px;">Srisawad Chatbot</h1>
        </div>
        """,
        unsafe_allow_html=True,
    )
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    if user_input := st.chat_input("Ask a question about cars or credit policy..."):
        st.session_state.user_question = user_input
        save_chat_to_history(st.session_state.current_chat_id, "user", user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})
        with chat_container:
            with st.chat_message("user"):
                st.markdown(user_input)
        with st.spinner("Analyzing your question..."):
            reformulated_question, detected_data_source, _ = route_query_to_appropriate_chain(user_input)
        with chat_container:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                message_placeholder.markdown("Processing your question...")
                if detected_data_source == "Car Rate":
                    car_chain = build_car_rag_chain()
                    if not car_chain or car_data.empty:
                        response = "Sorry, I can't access car price information at the moment. Please try again later."
                    else:
                        response = car_chain.invoke(reformulated_question) or "I couldn't find specific information about this car model or price."
                        if len(response) >= 10:
                            product_group, gcode = extract_vehicle_info(response, car_data)
                            response = build_car_response(response, product_group, gcode)
                    for i in range(len(response)):
                        message_placeholder.markdown(response[:i + 1])
                        time.sleep(0.015)
                    save_chat_to_history(st.session_state.current_chat_id, "assistant", response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.session_state.detected_mode = "Car Rate"
                    display_resource_cards()
                else:
                    policy_chain = load_policy_data()
                    if not policy_chain:
                        response = "Sorry, I can't access credit policy information at the moment. Please try again later."
                    else:
                        response = policy_chain.invoke({"input": reformulated_question})
                        answer = response.get("answer", "I couldn't find specific information about this policy.")
                        sources = {doc.metadata.get("source") for doc in response.get("context", []) if hasattr(doc, "metadata")}
                        source_text = "\n\n---\n**Reference Source:**" + ("\n" + "\n".join(f"- {source}" for source in sources) if sources else "\n- No specific sources found")
                        response = answer + source_text
                    for i in range(len(response)):
                        message_placeholder.markdown(response[:i + 1])
                        time.sleep(0.02)
                    save_chat_to_history(st.session_state.current_chat_id, "assistant", response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.session_state.detected_mode = "Credit Policy"
                    display_resource_cards()

if __name__ == "__main__":
    main()